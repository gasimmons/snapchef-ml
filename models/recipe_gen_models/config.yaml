batch_size: 32
lr: 1e-4
epochs: 5
model:
  embed_dim: 256
  hidden_dim: 512
  vocab_size: 5000

